#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, argparse, unicodedata, re, itertools, collections
from pathlib import Path
from typing import List, Dict, Any, Tuple
import pandas as pd

# ---------------- å·¥å…·å‡½æ•° ----------------

CH_PUNCT = "ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€œâ€â€˜â€™â€”â€¦Â·"
RE_WS_PUNCT = re.compile(rf"[{re.escape(CH_PUNCT)}\s]+")

def norm(s: str) -> str:
    """æ¸©å’Œè§„èŒƒåŒ–ï¼šNFKC + å»ä¸¤ç«¯ç©ºç™½ + å»è¿ç»­ç©ºç™½/ä¸­æ–‡æ ‡ç‚¹ï¼›ä¸æ”¹åŠ¨ä¸­æ–‡å¤§å°å†™ã€‚"""
    if s is None:
        return ""
    s = unicodedata.normalize("NFKC", str(s)).strip()
    s = RE_WS_PUNCT.sub("", s)
    return s

def safe_list(x):
    if x is None: return []
    if isinstance(x, list): return x
    return [x]

def read_excel_disease_set(xlsx_path: Path) -> Tuple[Dict[str,str], List[str]]:
    """
    è¿”å›:
      sel_map: è§„èŒƒåŒ–å -> æ˜¾ç¤ºåï¼ˆæ¥è‡ªExcelâ€œç—…ä¾‹åº“åŒ¹é…æ•°æ®_*â€åˆ—ï¼‰
      cols_used: å®é™…æŠ“å–åˆ°çš„â€œç—…ä¾‹åº“åŒ¹é…æ•°æ®_*â€åˆ—å
    """
    df = pd.read_excel(xlsx_path)
    # æ‰¾æ‰€æœ‰â€œç—…ä¾‹åº“åŒ¹é…æ•°æ®_*â€åˆ—
    match_cols = [c for c in df.columns if str(c).startswith("ç—…ä¾‹åº“åŒ¹é…æ•°æ®")]
    if not match_cols:
        raise ValueError("Excel ä¸­æœªæ‰¾åˆ°ä»»ä½• 'ç—…ä¾‹åº“åŒ¹é…æ•°æ®_*' åˆ—")

    sel_map: Dict[str,str] = {}
    for c in match_cols:
        for v in df[c].dropna().astype(str):
            vv = v.strip()
            if not vv: continue
            sel_map.setdefault(norm(vv), vv)  # ç”¨Excelé‡Œå‡ºç°çš„åŸæ ·è¯ä½œæ˜¾ç¤ºå
    return sel_map, match_cols

def iter_records_from_json_dir(json_dir: Path):
    """éå†ç›®å½•ä¸‹æ‰€æœ‰ .jsonï¼Œyield æ¯æ¡ RECORDï¼ˆé™„æ–‡ä»¶æ¥æºï¼‰ã€‚"""
    for fp in sorted(json_dir.glob("**/*.json")):
        try:
            data = json.loads(fp.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"âš ï¸ è§£æå¤±è´¥ï¼Œè·³è¿‡: {fp} ({e})")
            continue
        recs = data.get("RECORDS", [])
        if isinstance(recs, list):
            for r in recs:
                yield fp, r
        else:
            print(f"âš ï¸ éæœŸæœ›ç»“æ„ï¼ˆæ—  RECORDS åˆ—è¡¨ï¼‰ï¼Œè·³è¿‡: {fp}")

# ---------------- ä¸»æµç¨‹ ----------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--xlsx", required=True, help="åŒ…å« 'ç—…ä¾‹åº“åŒ¹é…æ•°æ®_*' åˆ—çš„ Excel æ–‡ä»¶è·¯å¾„")
    ap.add_argument("--json_dir", required=True, help="ç—…ä¾‹åº“ JSON æ–‡ä»¶å¤¹ï¼ˆé€’å½’è¯»å– *.jsonï¼‰")
    ap.add_argument("--output_dir", default="./case_prob_out", help="è¾“å‡ºç›®å½•")
    args = ap.parse_args()

    out_dir = Path(args.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) ä» Excel æ”¶é›†è¦ä¿ç•™çš„ç–¾ç—…é›†åˆ
    sel_map, used_cols = read_excel_disease_set(Path(args.xlsx))  # norm_name -> display_name
    sel_norm_set = set(sel_map.keys())
    print(f"âœ… Excel è¯»å–å®Œæˆï¼šåŒ¹é…åˆ— {len(used_cols)} ä¸ªï¼Œå€™é€‰ç–¾ç—… {len(sel_norm_set)} ä¸ª")

    # 2) è¿‡æ»¤ç—…ä¾‹ï¼šåªä¿ç•™å«ç›®æ ‡ç–¾ç—…çš„ç—…ä¾‹ï¼Œå¹¶è£å‰ª final_disease
    kept_records: List[Dict[str, Any]] = []
    for src_fp, rec in iter_records_from_json_dir(Path(args.json_dir)):
        final_dis = [d for d in safe_list(rec.get("final_disease")) if isinstance(d, str) and d.strip()]
        if not final_dis:
            continue
        # è£å‰ªåˆ°ç›®æ ‡ç–¾ç—…é›†åˆ
        kept_displays = []
        for d in final_dis:
            dn = norm(d)
            if dn in sel_norm_set:
                kept_displays.append(sel_map[dn])  # ç»Ÿä¸€æ˜¾ç¤ºåä¸ºExcelç‰ˆæœ¬
        if not kept_displays:
            continue  # è¯¥ç—…ä¾‹ä¸å«ç›®æ ‡ç–¾ç—…ï¼Œä¸¢å¼ƒ

        # å‡†å¤‡è¾“å‡ºä¸€æ¡â€œè£å‰ªåâ€çš„è®°å½•
        new_rec = dict(rec)  # æµ…æ‹·è´å³å¯
        new_rec["final_disease"] = sorted(set(kept_displays))  # å»é‡ + æ’åº
        # è§„èŒƒåŒ–ç—‡çŠ¶ï¼šä»…å»ä¸¤ç«¯ç©ºç™½ï¼ˆä¸åšæ¿€è¿›å½’ä¸€ï¼‰
        final_sym = [s.strip() for s in safe_list(rec.get("final_symptom")) if isinstance(s, str) and s.strip()]
        new_rec["final_symptom"] = sorted(set(final_sym))
        new_rec["_source_file"] = str(src_fp)
        kept_records.append(new_rec)

    if not kept_records:
        print("â—æœªä¿ç•™åˆ°ä»»ä½•ç—…ä¾‹ã€‚è¯·æ£€æŸ¥ Excel ç–¾ç—…åç§°ä¸ç—…ä¾‹åº“ä¸­çš„åç§°æ˜¯å¦ä¸€è‡´ã€‚")
        return

    # ä¿å­˜è¿‡æ»¤åçš„ç—…ä¾‹ï¼ˆä¾¿äºå¤æ ¸ï¼‰
    filtered_path = out_dir / "filtered_cases.jsonl"
    with filtered_path.open("w", encoding="utf-8") as f:
        for r in kept_records:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    print(f"âœ… å·²è¾“å‡ºè¿‡æ»¤åçš„ç—…ä¾‹ï¼š{filtered_path}ï¼ˆ{len(kept_records)} æ¡ï¼‰")

    # 3) ç»Ÿè®¡å¹¶è®¡ç®—æ¦‚ç‡
    N = len(kept_records)  # æ¦‚ç‡åˆ†æ¯ï¼šä¿ç•™ç—…ä¾‹æ€»æ•°ï¼ˆå¤šæ ‡ç­¾å…è®¸âˆ‘P(D)>1ï¼‰

    # 3.1 ç–¾ç—…å…ˆéªŒ P(D)
    disease_counts = collections.Counter()
    for r in kept_records:
        disease_counts.update(r["final_disease"])
    disease_prior = {d: disease_counts[d] / N for d in sorted(disease_counts)}

    # 3.2 ç—‡çŠ¶å…ˆéªŒ P(S)
    symptom_counts = collections.Counter()
    for r in kept_records:
        symptom_counts.update(set(r["final_symptom"]))  # ä¸€æ¡ç—…ä¾‹å†…é‡å¤åªè®¡ä¸€æ¬¡
    symptom_prior = {s: symptom_counts[s] / N for s in sorted(symptom_counts)}

    # 3.3 æ¡ä»¶æ¦‚ç‡ P(S|D)
    #   å¯¹æ¯ä¸ªç–¾ç—…ï¼Œè®¡ç®—å…¶å‡ºç°çš„ç—…ä¾‹æ•°ä½œåˆ†æ¯ï¼›åˆ†å­ä¸ºåŒæ—¶å«è¯¥ç–¾ç—…ä¸”ç—‡çŠ¶å‡ºç°çš„ç—…ä¾‹æ•°
    cond_counts: Dict[str, collections.Counter] = {d: collections.Counter() for d in disease_counts}
    for r in kept_records:
        sym_set = set(r["final_symptom"])
        dis_set = set(r["final_disease"])
        for d in dis_set:
            cond_counts[d].update(sym_set)
    cond_prob_long = []  # é•¿è¡¨
    cond_prob_wide = {}  # å®½è¡¨ï¼šdisease -> {symptom: prob}
    for d in sorted(disease_counts):
        denom = disease_counts[d]
        row = {}
        for s in sorted(symptom_counts):
            num = cond_counts[d][s]
            p = (num / denom) if denom > 0 else 0.0
            row[s] = p
            cond_prob_long.append({"disease": d, "symptom": s, "p_s_given_d": p, "num": num, "den": denom})
        cond_prob_wide[d] = row

    # 3.4 ç—‡çŠ¶-ç—‡çŠ¶è”åˆæ¦‚ç‡ P(S_i, S_j)
    pair_counts = collections.Counter()
    for r in kept_records:
        sym_list = sorted(set(r["final_symptom"]))
        for a, b in itertools.combinations(sym_list, 2):
            pair_counts[(a, b)] += 1
    pair_prob_long = []
    for (a, b), c in sorted(pair_counts.items()):
        pair_prob_long.append({"symptom_i": a, "symptom_j": b, "p_joint": c / N, "count": c, "den": N})

    # 4) å¯¼å‡ºç»“æœ
    # 4.1 ç–¾ç—…å…ˆéªŒ
    df_dp = pd.DataFrame([{"disease": d, "count": disease_counts[d], "p_d": disease_prior[d]} for d in sorted(disease_prior)])
    df_dp.to_csv(out_dir / "disease_prior.csv", index=False, encoding="utf-8-sig")

    # 4.2 ç—‡çŠ¶å…ˆéªŒ
    df_sp = pd.DataFrame([{"symptom": s, "count": symptom_counts[s], "p_s": symptom_prior[s]} for s in sorted(symptom_prior)])
    df_sp.to_csv(out_dir / "symptom_prior.csv", index=False, encoding="utf-8-sig")

    # 4.3 æ¡ä»¶æ¦‚ç‡ï¼ˆé•¿/å®½ï¼‰
    df_cond_long = pd.DataFrame(cond_prob_long)
    df_cond_long.to_csv(out_dir / "cond_p_s_given_d_long.csv", index=False, encoding="utf-8-sig")

    # å®½è¡¨ï¼šè¡Œ=ç–¾ç—…ï¼Œåˆ—=ç—‡çŠ¶
    df_cond_wide = pd.DataFrame.from_dict(cond_prob_wide, orient="index").reset_index().rename(columns={"index":"disease"})
    df_cond_wide.to_csv(out_dir / "cond_p_s_given_d_wide.csv", index=False, encoding="utf-8-sig")

    # 4.4 ç—‡çŠ¶è”åˆæ¦‚ç‡
    df_pair = pd.DataFrame(pair_prob_long)
    df_pair.to_csv(out_dir / "symptom_joint_prob.csv", index=False, encoding="utf-8-sig")

    # 4.5 ä¹Ÿå­˜ä¸€ä»½ JSON ä¾¿äºç¨‹åºè¯»
    (out_dir / "probabilities.json").write_text(json.dumps({
        "meta": {
            "num_records": N,
            "note": "å¤šæ ‡ç­¾è®¡æ•°ï¼šåŒä¸€ç—…ä¾‹å«å¤šä¸ªç–¾ç—…åˆ™æ¯ä¸ªç–¾ç—…éƒ½è®¡ä¸€æ¬¡ã€‚"
        },
        "disease_prior": df_dp.to_dict(orient="records"),
        "symptom_prior": df_sp.to_dict(orient="records"),
        "cond_p_s_given_d": df_cond_long.to_dict(orient="records"),
        "symptom_joint": df_pair.to_dict(orient="records"),
    }, ensure_ascii=False, indent=2), encoding="utf-8")

    print("âœ… æ¦‚ç‡å·²è®¡ç®—å®Œæˆ")
    print(f"ğŸ“„ è¾“å‡ºç›®å½•ï¼š{out_dir}")
    print("  - disease_prior.csv")
    print("  - symptom_prior.csv")
    print("  - cond_p_s_given_d_long.csv / cond_p_s_given_d_wide.csv")
    print("  - symptom_joint_prob.csv")
    print("  - filtered_cases.jsonlï¼ˆè¿‡æ»¤åçš„ç—…ä¾‹ï¼‰")
    print("  - probabilities.jsonï¼ˆæ±‡æ€» JSONï¼‰")

if __name__ == "__main__":
    main()
